{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшенный бенчмарк\n",
    "\n",
    "Для задачи **Digital Reputation Challenge**\n",
    "\n",
    "https://boosters.pro\n",
    "\n",
    "автор: Дарья Соболева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 26) (462888, 2) (4000, 453) (4000, 6)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = 'train/'\n",
    "X1 = pd.read_csv(TRAIN_PATH + 'X1.csv')\n",
    "X2 = pd.read_csv(TRAIN_PATH + 'X2.csv')\n",
    "X3 = pd.read_csv(TRAIN_PATH + 'X3.csv')\n",
    "Y = pd.read_csv(TRAIN_PATH + 'Y.csv')\n",
    "print (X1.shape, X2.shape, X3.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.columns = ['Y' + s if s != 'id' else 'id' for s in Y.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4058, 26) (470083, 2) (4058, 453)\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = 'test/'\n",
    "X1_test = pd.read_csv(TEST_PATH + 'X1.csv')\n",
    "X2_test = pd.read_csv(TEST_PATH + 'X2.csv')\n",
    "X3_test = pd.read_csv(TEST_PATH + 'X3.csv')\n",
    "print (X1_test.shape, X2_test.shape, X3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_all = pd.concat([X2, X2_test], axis=0)\n",
    "\n",
    "X2_user_ids, X2_counts = np.unique(X2_all['id'], return_counts=True)\n",
    "url_count = np.hstack((X2_user_ids.reshape(-1, 1), X2_counts.reshape(-1, 1)))\n",
    "url_count_df = pd.DataFrame(data=url_count, columns=['id', 'Counter'])\n",
    "\n",
    "X1 = X1.merge(url_count_df, on='id', how='left')\n",
    "X1_test = X1_test.merge(url_count_df, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "model.fit(X1[X1.columns.difference(['id', 'Counter'])], y1)\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_, X1.columns.difference(['id', 'Counter'])))[-20:], columns=['Value','Feature'])\n",
    "\n",
    "feature_imp = feature_imp.sort_values(by=\"Value\", ascending=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp, orient='h')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y1\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y2\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y3\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y5\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y1\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y2\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y3\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y5\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y1\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y2\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y3\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y5\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y1\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y2\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y3\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y4\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n",
      "Y5\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "8\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_and_plot_important_features(X, y, verbose=False, n=1):\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=1000, n_jobs=-1)\n",
    "    model.fit(X[X.columns.difference(['id', 'Counter'])], y)\n",
    "\n",
    "    feature_imp = pd.DataFrame(sorted(zip(model.feature_importances_, X.columns.difference(['id', 'Counter'])))[-10:], columns=['Value','Feature'])\n",
    "\n",
    "    feature_imp = feature_imp.sort_values(by=\"Value\", ascending=False)\n",
    "    \n",
    "    if verbose:\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp, orient='h')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    #return [feature_imp.Feature.iloc[0]]\n",
    "    return list(feature_imp.Feature[:n])\n",
    "    \n",
    "\n",
    "def stat_imp_features(imp_features, cls, X, X_test, f):\n",
    "    X_all = pd.concat([X, X_test], axis=0)\n",
    "    \n",
    "    X_f_counts = X[f].value_counts().to_frame()\n",
    "    X_f_counts = X_f_counts.reset_index()\n",
    "    X_f_counts.columns = [f, 'Count']\n",
    "\n",
    "    X_f_counts_filtered = X_f_counts[X_f_counts.Count > 25]\n",
    "    cols = list(set(X1.columns) & set(imp_features1))\n",
    "    X_merged = pd.merge(X[X.columns.difference(cols)], X_f_counts_filtered, how='right', on=f)\n",
    "    X_merged = pd.merge(X_merged, X1[['id'] + imp_features], how='left', on='id')\n",
    "    \n",
    "    funcs = [np.mean, np.sum] # np.median#[np.mean, np.max, np.min, np.std]\n",
    "    \n",
    "    grouped_f = X_merged.groupby(f)\n",
    "\n",
    "    X_all = X_all.set_index(f)\n",
    "    \n",
    "    print(cls)\n",
    "    for imp_feature in imp_features:\n",
    "        print(imp_feature)\n",
    "        \n",
    "        for func in funcs:\n",
    "            #print(func.__name__)\n",
    "            stat = grouped_f[imp_feature].apply(lambda x: func(x))\n",
    "            #return X2_all, stat\n",
    "            #print(func, imp_feature)\n",
    "            X_all['{}_{}'.format(imp_feature, func.__name__)] = stat\n",
    "        \n",
    "    X_all = X_all.reset_index()\n",
    "    grouped_id = X_all.groupby('id')\n",
    "    \n",
    "    res = X_all[['id']].drop_duplicates().set_index('id')\n",
    "    imp_features1_list = []\n",
    "    \n",
    "    for imp_feature in imp_features:\n",
    "        print(imp_feature)\n",
    "        for func1 in funcs:\n",
    "            for func2 in funcs:\n",
    "                #print(imp_feature, func1.__name__, func2.__name__)\n",
    "                stat_stat = grouped_id['{}_{}'.format(imp_feature, func1.__name__)].apply(lambda x: func2(x))\n",
    "                f = '{}_{}_{}_{}_{}'.format(imp_feature, func1.__name__, func2.__name__, cls, f)\n",
    "                res[f] = stat_stat\n",
    "                imp_features1_list.append(f)\n",
    "        \n",
    "    return res.reset_index(), imp_features1_list\n",
    "    \n",
    "X = X1.merge(Y)\n",
    "\n",
    "id_ = X.pop('id')\n",
    "y1 = X.pop('Y1')\n",
    "y2 = X.pop('Y2')\n",
    "y3 = X.pop('Y3')\n",
    "y4 = X.pop('Y4')\n",
    "y5 = X.pop('Y5')\n",
    "\n",
    "# model1 = lgb.LGBMClassifier(learning_rate=0.01, num_leaves=12,\n",
    "#                             n_estimators=290,\n",
    "#                             colsample_bytree=0.75, subsample=0.75, random_state=0, n_jobs=-1)\n",
    "\n",
    "imp_features1 = get_and_plot_important_features(X, y1, verbose=False, n=3)\n",
    "#imp_features1 += ['5', '7', '3', 'Counter']\n",
    "statA_imp_features1, impA_features1 = stat_imp_features(imp_features1, 'Y1', X2, X2_test, 'A')\n",
    "\n",
    "imp_features2 = get_and_plot_important_features(X, y2, verbose=False, n=3)\n",
    "#imp_features2 += ['5', '7', '3', 'Counter']\n",
    "statA_imp_features2, impA_features2 = stat_imp_features(imp_features2, 'Y2', X2, X2_test, 'A')\n",
    "\n",
    "imp_features3 = get_and_plot_important_features(X, y3, verbose=False, n=3)\n",
    "#imp_features3 += ['5', '7', '3', 'Counter']\n",
    "statA_imp_features3, impA_features3 = stat_imp_features(imp_features3, 'Y3', X2, X2_test, 'A')\n",
    "\n",
    "imp_features4 = get_and_plot_important_features(X, y4, verbose=False, n=3)\n",
    "#imp_features4 += ['5', '7', '3', 'Counter']\n",
    "statA_imp_features4, impA_features4 = stat_imp_features(imp_features4, 'Y4', X2, X2_test, 'A')\n",
    "\n",
    "imp_features5 = get_and_plot_important_features(X, y5, verbose=False, n=3)\n",
    "#imp_features5 += ['5', '7', '3', 'Counter']\n",
    "statA_imp_features5, impA_features5 = stat_imp_features(imp_features5, 'Y5', X2, X2_test, 'A')\n",
    "\n",
    "\n",
    "\n",
    "stat1_imp_features1, imp1_features1 = stat_imp_features(imp_features1, 'Y1', X1, X1_test, '1')\n",
    "stat1_imp_features2, imp1_features2 = stat_imp_features(imp_features2, 'Y2', X1, X1_test, '1')\n",
    "stat1_imp_features3, imp1_features3 = stat_imp_features(imp_features3, 'Y3', X1, X1_test, '1')\n",
    "stat1_imp_features4, imp1_features4 = stat_imp_features(imp_features4, 'Y4', X1, X1_test, '1')\n",
    "stat1_imp_features5, imp1_features5 = stat_imp_features(imp_features5, 'Y5', X1, X1_test, '1')\n",
    "\n",
    "stat13_imp_features1, imp13_features1 = stat_imp_features(imp_features1, 'Y1', X1, X1_test, '13')\n",
    "stat13_imp_features2, imp13_features2 = stat_imp_features(imp_features2, 'Y2', X1, X1_test, '13')\n",
    "stat13_imp_features3, imp13_features3 = stat_imp_features(imp_features3, 'Y3', X1, X1_test, '13')\n",
    "stat13_imp_features4, imp13_features4 = stat_imp_features(imp_features4, 'Y4', X1, X1_test, '13')\n",
    "stat13_imp_features5, imp13_features5 = stat_imp_features(imp_features5, 'Y5', X1, X1_test, '13')\n",
    "\n",
    "stat22_imp_features1, imp22_features1 = stat_imp_features(imp_features1, 'Y1', X1, X1_test, '22')\n",
    "stat22_imp_features2, imp22_features2 = stat_imp_features(imp_features2, 'Y2', X1, X1_test, '22')\n",
    "stat22_imp_features3, imp22_features3 = stat_imp_features(imp_features3, 'Y3', X1, X1_test, '22')\n",
    "stat22_imp_features4, imp22_features4 = stat_imp_features(imp_features4, 'Y4', X1, X1_test, '22')\n",
    "stat22_imp_features5, imp22_features5 = stat_imp_features(imp_features5, 'Y5', X1, X1_test, '22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on popularity\n",
    "\n",
    "X2_all = X2.append(X2_test)\n",
    "\n",
    "A_top_100 = X2_all.A.value_counts()[:20].to_frame()\n",
    "A_top_100 = A_top_100.reset_index()\n",
    "A_top_100.columns = ['A', 'count']\n",
    "\n",
    "X2_top_100 = X2_all.merge(A_top_100, on='A', how='inner')\n",
    "X2_top_100_dummies = pd.get_dummies(X2_top_100[['id', 'A']], columns=['A'])\n",
    "X2_top_100_dummies = X2_top_100_dummies.groupby('id').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter on Y\n",
    "def get_filtered_dummies(X2_Y, target):\n",
    "    Y_A_count_class = X2_Y[X2_Y[target] == 1].groupby('A').size().to_frame()\n",
    "    Y_A_count_class = Y_A_count_class.reset_index()\n",
    "    Y_A_count_class.columns = ['A', 'count_class_1']\n",
    "    Y_A_count_filtered = Y_A_count_class[Y_A_count_class.count_class_1 >= 25]\n",
    "\n",
    "    Y_A_count = X2_Y.groupby('A').size().to_frame()\n",
    "    Y_A_count = Y_A_count.reset_index()\n",
    "    Y_A_count.columns = ['A', 'count']\n",
    "    Y_A_count_filtered = Y_A_count_filtered.merge(Y_A_count, on='A', how='left')\n",
    "    Y_A_count_filtered['ctr_count'] = Y_A_count_filtered['count_class_1'] / Y_A_count_filtered['count'] \n",
    "\n",
    "\n",
    "    A_top_100_left = Y_A_count_filtered.sort_values('ctr_count', ascending=False)[:30]\n",
    "    A_top_100_right = Y_A_count_filtered.sort_values('ctr_count', ascending=False)[-30:]\n",
    "    A_top_100 = pd.concat([A_top_100_left, A_top_100_right], axis=0)\n",
    "    A_top_100 = A_top_100[['A', 'ctr_count']]\n",
    "\n",
    "    X2_top_100 = X2.merge(A_top_100, on='A', how='inner')\n",
    "    X2_top_100_dummies = pd.get_dummies(X2_top_100[['id', 'A']], columns=['A'], prefix_sep='_' + target + '_')\n",
    "    X2_top_100_dummies = X2_top_100_dummies.groupby('id').sum().reset_index()\n",
    "    \n",
    "    X2_test_top_100 = X2_test.merge(A_top_100, on='A', how='inner')\n",
    "    X2_test_top_100_dummies = pd.get_dummies(X2_test_top_100[['id', 'A']], columns=['A'], prefix_sep='_' + target + '_')\n",
    "    X2_test_top_100_dummies = X2_test_top_100_dummies.groupby('id').sum().reset_index()\n",
    "    \n",
    "    features = list(X2_top_100_dummies.columns.difference(['id']))\n",
    "    return X2_top_100_dummies, X2_test_top_100_dummies, features\n",
    "    \n",
    "X2_Y = X2.merge(Y, how='left', on='id')\n",
    "\n",
    "X2_top_100_dummies1, X2_test_top_100_dummies1, features1 = get_filtered_dummies(X2_Y, 'Y1')\n",
    "X2_top_100_dummies2, X2_test_top_100_dummies2, features2 = get_filtered_dummies(X2_Y, 'Y2')\n",
    "X2_top_100_dummies3, X2_test_top_100_dummies3, features3 = get_filtered_dummies(X2_Y, 'Y3')\n",
    "X2_top_100_dummies4, X2_test_top_100_dummies4, features4 = get_filtered_dummies(X2_Y, 'Y4')\n",
    "X2_top_100_dummies5, X2_test_top_100_dummies5, features5 = get_filtered_dummies(X2_Y, 'Y5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count user\n",
    "\n",
    "X2_user_count = X2_all.id.value_counts().to_frame()\n",
    "X2_user_count = X2_user_count.reset_index()\n",
    "X2_user_count.columns = ['id', 'count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка обучения и теста\n",
    "\n",
    "используем только матрицу 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X1.copy()\n",
    "base_features = list(X.columns.difference(['id']))\n",
    "\n",
    "X = X.merge(statA_imp_features1, on='id', how='left')\n",
    "X = X.merge(statA_imp_features2, on='id', how='left')\n",
    "X = X.merge(statA_imp_features3, on='id', how='left')\n",
    "X = X.merge(statA_imp_features4, on='id', how='left')\n",
    "X = X.merge(statA_imp_features5, on='id', how='left')\n",
    "\n",
    "X = X.merge(stat22_imp_features1, on='id', how='left')\n",
    "X = X.merge(stat22_imp_features2, on='id', how='left')\n",
    "X = X.merge(stat22_imp_features3, on='id', how='left')\n",
    "X = X.merge(stat22_imp_features4, on='id', how='left')\n",
    "X = X.merge(stat22_imp_features5, on='id', how='left')\n",
    "\n",
    "X = X.merge(stat1_imp_features1, on='id', how='left')\n",
    "X = X.merge(stat1_imp_features2, on='id', how='left')\n",
    "X = X.merge(stat1_imp_features3, on='id', how='left')\n",
    "X = X.merge(stat1_imp_features4, on='id', how='left')\n",
    "X = X.merge(stat1_imp_features5, on='id', how='left')\n",
    "\n",
    "X = X.merge(stat13_imp_features1, on='id', how='left')\n",
    "X = X.merge(stat13_imp_features2, on='id', how='left')\n",
    "X = X.merge(stat13_imp_features3, on='id', how='left')\n",
    "X = X.merge(stat13_imp_features4, on='id', how='left')\n",
    "X = X.merge(stat13_imp_features5, on='id', how='left')\n",
    "\n",
    "X = X.merge(X2_top_100_dummies1, on='id', how='left')\n",
    "X = X.merge(X2_top_100_dummies2, on='id', how='left')\n",
    "X = X.merge(X2_top_100_dummies3, on='id', how='left')\n",
    "X = X.merge(X2_top_100_dummies4, on='id', how='left')\n",
    "X = X.merge(X2_top_100_dummies5, on='id', how='left')\n",
    "\n",
    "X.fillna(0.0, inplace=True, axis=0)\n",
    "#X = X.merge(X2_user_count, on='id', how='left')\n",
    "\n",
    "X = X.merge(Y)\n",
    "\n",
    "id_ = X.pop('id')\n",
    "y1 = X.pop('Y1')\n",
    "y2 = X.pop('Y2')\n",
    "y3 = X.pop('Y3')\n",
    "y4 = X.pop('Y4')\n",
    "y5 = X.pop('Y5')\n",
    "\n",
    "X_test = X1_test.copy()\n",
    "\n",
    "X_test = X_test.merge(statA_imp_features1, on='id', how='left')\n",
    "X_test = X_test.merge(statA_imp_features2, on='id', how='left')\n",
    "X_test = X_test.merge(statA_imp_features3, on='id', how='left')\n",
    "X_test = X_test.merge(statA_imp_features4, on='id', how='left')\n",
    "X_test = X_test.merge(statA_imp_features5, on='id', how='left')\n",
    "\n",
    "X_test = X_test.merge(stat22_imp_features1, on='id', how='left')\n",
    "X_test = X_test.merge(stat22_imp_features2, on='id', how='left')\n",
    "X_test = X_test.merge(stat22_imp_features3, on='id', how='left')\n",
    "X_test = X_test.merge(stat22_imp_features4, on='id', how='left')\n",
    "X_test = X_test.merge(stat22_imp_features5, on='id', how='left')\n",
    "\n",
    "X_test = X_test.merge(stat1_imp_features1, on='id', how='left')\n",
    "X_test = X_test.merge(stat1_imp_features2, on='id', how='left')\n",
    "X_test = X_test.merge(stat1_imp_features3, on='id', how='left')\n",
    "X_test = X_test.merge(stat1_imp_features4, on='id', how='left')\n",
    "X_test = X_test.merge(stat1_imp_features5, on='id', how='left')\n",
    "\n",
    "X_test = X_test.merge(stat13_imp_features1, on='id', how='left')\n",
    "X_test = X_test.merge(stat13_imp_features2, on='id', how='left')\n",
    "X_test = X_test.merge(stat13_imp_features3, on='id', how='left')\n",
    "X_test = X_test.merge(stat13_imp_features4, on='id', how='left')\n",
    "X_test = X_test.merge(stat13_imp_features5, on='id', how='left')\n",
    "\n",
    "X_test = X_test.merge(X2_test_top_100_dummies1, on='id', how='left')\n",
    "X_test = X_test.merge(X2_test_top_100_dummies2, on='id', how='left')\n",
    "X_test = X_test.merge(X2_test_top_100_dummies3, on='id', how='left')\n",
    "X_test = X_test.merge(X2_test_top_100_dummies4, on='id', how='left')\n",
    "X_test = X_test.merge(X2_test_top_100_dummies5, on='id', how='left')\n",
    "\n",
    "X_test.fillna(0.0, inplace=True, axis=0)\n",
    "\n",
    "# X_test = X_test.merge(X2_user_count, on='id', how='left')\n",
    "\n",
    "id__ = X_test.pop('id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперименты\n",
    "\n",
    "делаются так..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "def colsample_fit(X_train, y_train, X_test, param, random_state):\n",
    "    final_pred = []\n",
    "    w = [0.4, 0.5, 0.7, 0.8, 0.9]\n",
    "    for colsample_bytree in w:\n",
    "        param['colsample_bytree'] = colsample_bytree\n",
    "        estimator = lgb.LGBMClassifier(**param, n_jobs=-1, random_state=random_state)\n",
    "        estimator.fit(X_train.values, y_train.values)\n",
    "        pred_statement = estimator.predict_proba(X_test.values)[:, 1]\n",
    "        final_pred.append(pred_statement)\n",
    "        \n",
    "    final_pred = np.sum(np.array(final_pred).T * np.array(w), axis=1) / np.sum(w)\n",
    "    param['colsample_bytree'] = 0.75\n",
    "    estimator = lgb.LGBMClassifier(**param, n_jobs=-1, random_state=random_state)\n",
    "    estimator.fit(X_train.values, y_train.values)\n",
    "    pred_statement = estimator.predict_proba(X_test.values)[:, 1]\n",
    "    final_pred = (np.array(final_pred) + pred_statement) / 2.0\n",
    "    return final_pred\n",
    "\n",
    "def cv_default(param, X, y, n_splits=10, random_state=0):\n",
    "    estimator = lgb.LGBMClassifier(**param, n_jobs=-1, random_state=random_state)\n",
    "    \n",
    "    cv = KFold(n_splits=n_splits, shuffle=False, random_state=random_state)\n",
    "    cv_iter = list(cv.split(X, y))\n",
    "    \n",
    "    scores = []\n",
    "\n",
    "    for train, test in cv_iter:\n",
    "        estimator.fit(X.iloc[train, :].values, y.iloc[train].values)\n",
    "        \n",
    "        y_statement = y.iloc[test]\n",
    "        pred_statement = estimator.predict_proba(X.iloc[test, :].values)[:, 1]\n",
    "        \n",
    "        #pred_statement = colsample_fit(X.iloc[train, :], y.iloc[train], X.iloc[test, :], param, random_state)\n",
    "        scores.append(roc_auc_score(y_statement, pred_statement))\n",
    "        \n",
    "    return np.mean(np.array(scores))\n",
    "\n",
    "def cv(param, X, y, nfold=50, random_state=0):\n",
    "    w = lgb.cv(param, lgb.Dataset(X, label=y), stratified=False,\n",
    "           num_boost_round=1000, nfold=nfold, seed=random_state) \n",
    "    return max(w['auc-mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'num_leaves': 8, 'objective': 'binary', 'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25, 'metric': 'auc'}\n",
      "{'n_estimators': 1000, 'num_leaves': 4, 'objective': 'binary', 'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25, 'metric': 'auc'}\n",
      "{'n_estimators': 1000, 'num_leaves': 6, 'objective': 'binary', 'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25, 'metric': 'auc'}\n",
      "{'n_estimators': 1000, 'num_leaves': 2, 'objective': 'binary', 'learning_rate': 0.05, 'colsample_bytree': 0.25, 'subsample': 0.25, 'metric': 'auc'}\n",
      "{'n_estimators': 1000, 'num_leaves': 3, 'objective': 'binary', 'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25, 'metric': 'auc'}\n",
      "[0.6112750112833022, 0.5910309889576648, 0.6276192753967939, 0.596384531128654, 0.5632067605889531]\n",
      "0.5979033134710736\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import operator\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary', \n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75, \n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary', \n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary', \n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = {}\n",
    "for num_leaves in list(range(4, 12, 2)) + list(range(12, 22, 2)):\n",
    "    for colsample_bytree in [0.25, 0.5, 0.75, 1.0]:\n",
    "        for subsample in [0.25, 0.5, 0.75, 1.0]:\n",
    "            param1['num_leaves'] = num_leaves\n",
    "            param1['colsample_bytree'] = colsample_bytree\n",
    "            param1['subsample'] = subsample\n",
    "            scores[(num_leaves, colsample_bytree, subsample)] = cv(param1, X[base_features+features1+impA_features1], y1)\n",
    "    \n",
    "best_param1 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "param1['num_leaves'],param1['colsample_bytree'],param1['subsample'] =  best_param1\n",
    "print(param1)\n",
    "\n",
    "scores = {}\n",
    "for num_leaves in range(2, 22, 2):\n",
    "    for colsample_bytree in [0.25, 0.5, 0.75, 1.0]:\n",
    "        for subsample in [0.25, 0.5, 0.75, 1.0]:\n",
    "            param2['num_leaves'] = num_leaves\n",
    "            param2['colsample_bytree'] = colsample_bytree\n",
    "            param2['subsample'] = subsample\n",
    "            scores[(num_leaves, colsample_bytree, subsample)] = cv(param2, X[base_features+features2+impA_features2], y2)\n",
    "    \n",
    "best_param2 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "param2['num_leaves'],param2['colsample_bytree'],param2['subsample'] =  best_param2\n",
    "print(param2)\n",
    "\n",
    "scores = {}\n",
    "for num_leaves in range(2, 22, 2):\n",
    "    for colsample_bytree in [0.25, 0.5, 0.75, 1.0]:\n",
    "        for subsample in [0.25, 0.5, 0.75, 1.0]:\n",
    "            param3['num_leaves'] = num_leaves\n",
    "            param3['colsample_bytree'] = colsample_bytree\n",
    "            param3['subsample'] = subsample\n",
    "            scores[(num_leaves, colsample_bytree, subsample)] = cv(param3, X[base_features+features3+impA_features3], y3)\n",
    "    \n",
    "best_param3 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "param3['num_leaves'],param3['colsample_bytree'],param3['subsample'] =  best_param3\n",
    "print(param3)\n",
    "\n",
    "scores = {}\n",
    "for num_leaves in range(2, 22, 2):\n",
    "    for colsample_bytree in [0.25, 0.5, 0.75, 1.0]:\n",
    "        for subsample in [0.25, 0.5, 0.75, 1.0]:\n",
    "            param4['num_leaves'] = num_leaves\n",
    "            param4['colsample_bytree'] = colsample_bytree\n",
    "            param4['subsample'] = subsample\n",
    "            scores[(num_leaves, colsample_bytree, subsample)] = cv(param4, X[base_features+features4+impA_features4], y4)\n",
    "    \n",
    "best_param4 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "param4['num_leaves'],param4['colsample_bytree'],param4['subsample'] =  best_param4\n",
    "print(param4)\n",
    "\n",
    "scores = {}\n",
    "for num_leaves in list(range(2, 22, 2)) + [3]:\n",
    "    for colsample_bytree in [0.25, 0.5, 0.75, 1.0]:\n",
    "        for subsample in [0.25, 0.5, 0.75, 1.0]:\n",
    "            param5['num_leaves'] = num_leaves\n",
    "            param5['colsample_bytree'] = colsample_bytree\n",
    "            param5['subsample'] = subsample\n",
    "            scores[(num_leaves, colsample_bytree, subsample)] = cv(param5, X[base_features+features5+impA_features5], y5)\n",
    "    \n",
    "best_param5 = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[0][0]\n",
    "param5['num_leaves'],param5['colsample_bytree'],param5['subsample'] =  best_param5\n",
    "print(param5)\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+impA_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+impA_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+impA_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+impA_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+impA_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.611167160375956, 0.6231362317196715, 0.6289643759321693, 0.6090848664491574, 0.5991151606187812]\n",
      "0.6142935590191471\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':8, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+impA_features1+imp22_features1+imp1_features1+imp13_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+impA_features2+imp22_features2+imp1_features2+imp13_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+impA_features3+imp22_features3+imp1_features3+imp13_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+impA_features4+imp22_features4+imp1_features4+imp13_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+impA_features5+imp22_features5+imp1_features5+imp13_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6151987165416142, 0.6255375497437743, 0.6294643818197097, 0.6110534107576142, 0.5978287230308484]\n",
      "0.6158165563787121\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':8, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 1.0, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.25, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.25,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+impA_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+impA_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+impA_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+impA_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+impA_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6117147709189317, 0.6179712744598408, 0.6234963962092699, 0.6062505810001484, 0.5978287230308484]\n",
      "0.6114523491238077\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+impA_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+impA_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+impA_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+impA_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+impA_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6105549166519464, 0.6178046936747414, 0.6221297335708857, 0.6064613444070113, 0.596969515411341]\n",
      "0.6107840407431852\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+impA_features1+imp12_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+impA_features2+imp12_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+impA_features3+imp12_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+impA_features4+imp12_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+impA_features5+imp12_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6127034478161006, 0.6192508465619226, 0.6216391078656591, 0.6116328259008149, 0.5968473220520154]\n",
      "0.6124147100393026\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+imp_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+imp_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+imp_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+imp_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+imp_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6130190380603134, 0.6232312248607247, 0.62373149578957, 0.6092623563089257, 0.5916564107714628]\n",
      "0.6121801051581993\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+imp_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+imp_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+imp_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+imp_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+imp_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6117147709189317, 0.6179712744598408, 0.6234963962092699, 0.6062505810001484, 0.5978287230308484]\n",
      "0.6114523491238077\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+imp_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+imp_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+imp_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+imp_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+imp_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6100815230545286, 0.6170958716713599, 0.6308808042155638, 0.603693786195624, 0.5931352309601315]\n",
      "0.6109774432194416\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+imp_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+imp_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+imp_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+imp_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+imp_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6240259295741233, 0.6139571266389168, 0.6291637769388758, 0.6056379019508451, 0.5808878306542964]\n",
      "0.6107345131514114\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1+imp_features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2+imp_features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3+imp_features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4+imp_features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5+imp_features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6095421349473995, 0.5995572731129474, 0.6302295279036401, 0.6038930272663179, 0.5630446440530276]\n",
      "0.6012533214566664\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X, y1))\n",
    "scores.append(cv(param2, X, y2))\n",
    "scores.append(cv(param3, X, y3))\n",
    "scores.append(cv(param4, X, y4))\n",
    "scores.append(cv(param5, X, y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6127615196443195, 0.607955257784282, 0.6285061161569343, 0.6008382052167156, 0.5635839587795958]\n",
      "0.6027290115163695\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':12, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X[base_features+features1], y1))\n",
    "scores.append(cv(param2, X[base_features+features2], y2))\n",
    "scores.append(cv(param3, X[base_features+features3], y3))\n",
    "scores.append(cv(param4, X[base_features+features4], y4))\n",
    "scores.append(cv(param5, X[base_features+features5], y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/engine.py:430: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.602379846937974, 0.5985401504911753, 0.6241238424504244, 0.6040459367879308, 0.5572908157669137]\n",
      "0.5972761184868837\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "param1 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':1000, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':1000, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':1000, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':1000, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.05, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv(param1, X, y1))\n",
    "scores.append(cv(param2, X, y2))\n",
    "scores.append(cv(param3, X, y3))\n",
    "scores.append(cv(param4, X, y4))\n",
    "scores.append(cv(param5, X, y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6106547050951469, 0.6018860071093031, 0.6169896178202073, 0.608072115564023, 0.5549038222792463]\n",
      "0.5985012535735852\n"
     ]
    }
   ],
   "source": [
    "param1 = {'n_estimators':290, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.01, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param2 = {'n_estimators':378, 'num_leaves':2, 'objective':'binary',\n",
    "         'learning_rate': 0.03, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param3 = {'n_estimators':543, 'num_leaves':4, 'objective':'binary',\n",
    "         'learning_rate': 0.01, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param4 = {'n_estimators':618, 'num_leaves':6, 'objective':'binary',\n",
    "         'learning_rate': 0.003, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "param5 = {'n_estimators':516, 'num_leaves':3, 'objective':'binary',\n",
    "         'learning_rate': 0.002, 'colsample_bytree': 0.75, 'subsample': 0.75,\n",
    "        'metric': 'auc'}\n",
    "\n",
    "scores = []\n",
    "scores.append(cv_default(param1, X, y1))\n",
    "scores.append(cv_default(param2, X, y2))\n",
    "scores.append(cv_default(param3, X, y3))\n",
    "scores.append(cv_default(param4, X, y4))\n",
    "scores.append(cv_default(param5, X, y5))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ff9b9ddd8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(w['auc-mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param1_final = param1.copy()\n",
    "param1_final['n_estimators']= 290\n",
    "param1_final['learning_rate'] = 0.01\n",
    "\n",
    "a1 = 0.0\n",
    "for t in range(10):\n",
    "    model1 = lgb.LGBMClassifier(**param1_final, random_state=t, n_jobs=-1)\n",
    "    model1.fit(X[base_features + features1 + impA_features1+imp22_features1+imp1_features1+imp13_features1], y1)\n",
    "    a = model1.predict_proba(X_test[base_features + features1 + impA_features1+imp22_features1+imp1_features1+imp13_features1])[:,1]\n",
    "    # print (a)\n",
    "    a1 += a\n",
    "a1 = a1 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "param2_final = param1.copy()\n",
    "param2_final['n_estimators']= 378\n",
    "param2_final['learning_rate'] = 0.03\n",
    "\n",
    "a2 = 0.0\n",
    "for t in range(10):\n",
    "    model2 = lgb.LGBMClassifier(**param2_final, random_state=t, n_jobs=-1)\n",
    "    model2.fit(X[base_features + features2 + impA_features2+imp22_features2+imp1_features2+imp13_features2], y2)\n",
    "    a = model2.predict_proba(X_test[base_features + features2 + impA_features2+imp22_features2+imp1_features2+imp13_features2])[:,1]\n",
    "    a2 += a\n",
    "a2 = a2 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param3_final = param1.copy()\n",
    "param3_final['n_estimators']= 543\n",
    "param3_final['learning_rate'] = 0.01\n",
    "\n",
    "a3 = 0.0\n",
    "for t in range(10):\n",
    "    model3 = lgb.LGBMClassifier(**param3_final, random_state=t, n_jobs=-1)\n",
    "    model3.fit(X[base_features + features3 + impA_features3+imp22_features3+imp1_features3+imp13_features3], y3)\n",
    "    a = model3.predict_proba(X_test[base_features + features3 + impA_features3+imp22_features3+imp1_features3+imp13_features3])[:,1]\n",
    "    a3 += a\n",
    "a3 = a3 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "param4_final = param1.copy()\n",
    "param4_final['n_estimators']= 618\n",
    "param4_final['learning_rate'] = 0.003\n",
    "\n",
    "a4 = 0.0\n",
    "for t in range(10):\n",
    "    model4 = lgb.LGBMClassifier(**param4_final, random_state=t, n_jobs=-1)\n",
    "    model4.fit(X[base_features + features4 + impA_features4+imp22_features4+imp1_features4+imp13_features4], y4)\n",
    "    a = model4.predict_proba(X_test[base_features + features4 + impA_features4+imp22_features4+imp1_features4+imp13_features4])[:,1]\n",
    "    a4 += a\n",
    "a4 = a4 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param5_final = param1.copy()\n",
    "param5_final['n_estimators']= 516\n",
    "param5_final['learning_rate'] = 0.002\n",
    "\n",
    "a5 = 0.0\n",
    "for t in range(10):\n",
    "    model5 = lgb.LGBMClassifier(**param5_final, random_state=t, n_jobs=-1)\n",
    "    model5.fit(X[base_features + features5 + impA_features5+imp22_features5+imp1_features5+imp13_features5], y5)\n",
    "    a = model5.predict_proba(X_test[base_features + features5 + impA_features5+imp22_features5+imp1_features5+imp13_features5])[:,1]\n",
    "    #print (a)\n",
    "    a5 += a\n",
    "a5 = a5 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.363210</td>\n",
       "      <td>0.205448</td>\n",
       "      <td>0.241331</td>\n",
       "      <td>0.276296</td>\n",
       "      <td>0.467333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.311129</td>\n",
       "      <td>0.117546</td>\n",
       "      <td>0.303775</td>\n",
       "      <td>0.253816</td>\n",
       "      <td>0.428307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>0.365771</td>\n",
       "      <td>0.227431</td>\n",
       "      <td>0.254291</td>\n",
       "      <td>0.396635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.268858</td>\n",
       "      <td>0.217250</td>\n",
       "      <td>0.238411</td>\n",
       "      <td>0.252173</td>\n",
       "      <td>0.443656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.343752</td>\n",
       "      <td>0.128236</td>\n",
       "      <td>0.566166</td>\n",
       "      <td>0.300778</td>\n",
       "      <td>0.401555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         1         2         3         4         5\n",
       "0   0  0.363210  0.205448  0.241331  0.276296  0.467333\n",
       "1   1  0.311129  0.117546  0.303775  0.253816  0.428307\n",
       "2   2  0.398452  0.365771  0.227431  0.254291  0.396635\n",
       "3   4  0.268858  0.217250  0.238411  0.252173  0.443656\n",
       "4   7  0.343752  0.128236  0.566166  0.300778  0.401555"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'id': X1_test.id.values,\n",
    "             '1': a1,\n",
    "             '2': a2,\n",
    "             '3': a3,\n",
    "             '4': a4,\n",
    "             '5': a5})\n",
    "df.to_csv('with_1_22_13_prev_colsample_0.75.csv', index=False)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
